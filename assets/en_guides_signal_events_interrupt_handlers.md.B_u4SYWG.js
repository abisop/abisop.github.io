import{_ as a,c as s,al as t,o as n}from"./chunks/framework.NFAqBSgQ.js";const u=JSON.parse('{"title":"Signaling Events from Interrupt Handlers","description":"","frontmatter":{},"headers":[],"relativePath":"en/guides/signal_events_interrupt_handlers.md","filePath":"en/guides/signal_events_interrupt_handlers.md"}'),o={name:"en/guides/signal_events_interrupt_handlers.md"};function i(r,e,p,l,h,c){return n(),s("div",null,e[0]||(e[0]=[t(`<h1 id="signaling-events-from-interrupt-handlers" tabindex="-1">Signaling Events from Interrupt Handlers <a class="header-anchor" href="#signaling-events-from-interrupt-handlers" aria-label="Permalink to &quot;Signaling Events from Interrupt Handlers&quot;">​</a></h1><p>Warning</p><p>Migrated from <a href="https://cwiki.apache.org/confluence/display/NUTTX/Signaling+Events+from+Interrupt+Handlers" target="_blank" rel="noreferrer">https://cwiki.apache.org/confluence/display/NUTTX/Signaling+Events+from+Interrupt+Handlers</a></p><h2 id="best-way-to-wake-multiple-threads-from-interrupt" tabindex="-1">Best way to wake multiple threads from interrupt? <a class="header-anchor" href="#best-way-to-wake-multiple-threads-from-interrupt" aria-label="Permalink to &quot;Best way to wake multiple threads from interrupt?&quot;">​</a></h2><blockquote><p>I want to make a character device driver that passes the same data to all tasks that are reading it. It is not so important whether the data is queued or if just latest sample is retrieved. Problem is just how to wake up the waiting threads.</p></blockquote><p>At the most primitive level, a thread can be waiting for a semaphore, a signal, or a message queue (not empty or not full). Then there are higher level wrappers around these like mutexes, semaphores, poll waits, etc. But under the hood those are the three fundamental wait mechanisms. Any could be used to accomplish what you want.</p><p>In NuttX, some additional effort was put into the design of the signalling side of each of the IPCs so that they could be easily used by interrupts handlers. This behavior is unique to NuttX; POSIX says nothing about interrupt handlers. As a result, we will be talking about primarily non-portable OS interfaces.</p><blockquote><p>So far I&#39;ve considered the following options:</p></blockquote><p>And you basically have gone through the list of wait mechanisms:</p><h2 id="message-queues" tabindex="-1">Message Queues <a class="header-anchor" href="#message-queues" aria-label="Permalink to &quot;Message Queues&quot;">​</a></h2><blockquote><p>1) Open a message queue when the device is opened (a new queue for each task) and keep them in a list. Post to a non-blocking endpoint of these queues in the ISR. Read from a blocking endpoint in the device <code>read()</code>. I would need to generate names for the message queues, as there doesn&#39;t seem to be anonymous message queues?</p></blockquote><p>When you start a project. It is a good idea to decide upon a common IPC mechanism to base your design on. POSIX message queues are one good choice to do that: Assign each thread a message queue and the <code>main()</code> of each thread simply waits on the message queue. It is a good architecture and used frequently.</p><p>However, I would probably avoid creating a lot of message queues just to support the interrupt level signaling. There are other ways to do that that do not use so much memory. So, if you have message queues, use them. If not, keep it simple.</p><p>In this case, your waiting task will block on a call to <code>mq_receive()</code> until a message is received. It will then wake up and can process the message. In the interrupt handler, it will call <code>mq_send()</code> when an event of interest occurs which will, in turn, wake up the waiting task.</p><p>Advantages of the use of message queues in this case are that 1) you can pass quite a lot of data in the message, and 2) it integrates well in a message-based application architecture. A disadvantage is that there is a limitation on the number of messages that can be sent from an interrupt handler so it is possible to get data overrun conditions, that is, more interrupt events may be received than can be reported with the available messages.</p><p>This limitation is due to the fact that you cannot allocate memory dynamically from an interrupt handler. Instead, interrupt handlers are limited to the use of pre-allocated messages. The number of pre-allocated messages is given by <code>CONFIG_PREALLOC_MQ_MSGS</code> + 8. The <code>CONFIG_PREALLOC_MQ_MSGS</code> can be used either by normal tasking logic or by interrupt level logic. The extra eight are an emergency pool for interrupt handling logic only (that value is not currently configurable).</p><p>If the task logic consumes all of the <code>CONFIG_PREALLOC_MQ_MSGS</code> messages, it will fall back to dynamically allocating messages at some cost to performance and deterministic behavior.</p><p>If the interrupt level consumes all of the <code>CONFIG_PREALLOC_MQ_MSGS</code> messages, it will fall back and use the emergency pool of 8 pre-allocated messages. If those are also exhausted, then the message will not be sent and an interrupt is effectively lost.</p><h2 id="semaphores" tabindex="-1">Semaphores <a class="header-anchor" href="#semaphores" aria-label="Permalink to &quot;Semaphores&quot;">​</a></h2><blockquote><p>2) Allocate a semaphore per each device open and keep them in a list. Post the semaphores when new data is available in a shared buffer. Read the data inside <code>sched_lock()</code>.</p></blockquote><p>If you don&#39;t have an architecture that uses message queues, and all of these threads are waiting only for the interrupt event and nothing else, then signaling semaphores would work fine too. You are basically using semaphores as condition variables in this case so you do have to be careful.</p><p>NOTE: You do not need multiple semaphores. You can do this with a single semaphore. If the semaphore is used for this purpose then you initialize it to zero:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sem_init(&amp;sem, 0, 0);</span></span>
<span class="line"><span>sem_setprotocol(&amp;sem, SEM_PRIO_NONE);</span></span></code></pre></div><p><code>sem_setprotocol()</code> is a non-standard NuttX function that should be called immediately after the <code>sem_init()</code>. The effect of this function call is to disable priority inheritance for that specific semaphore. There should then be no priority inheritance operations on this semaphore that is used for signaling. See [[/guide](]{.title-ref}/guide.md)s/signaling_sem_priority_inheritance\` for further information.</p><p>Since the semaphore is initialized to zero, each time that a thread joins the group of waiting threads, the count is decremented. So a simple loop like this would wake up all waiting threads:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>int svalue;</span></span>
<span class="line"><span>int ret;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>for (; ; )</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>    ret = sem_getvalue(&amp;sem, &amp;svalue);</span></span>
<span class="line"><span>    if (svalue &lt; 0)</span></span>
<span class="line"><span>    {</span></span>
<span class="line"><span>        sem_post(&amp;sem);</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>    else</span></span>
<span class="line"><span>    {</span></span>
<span class="line"><span>        break;</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span></code></pre></div><p>NOTE: This use of <code>sem_getvalue()</code> is not portable. In many environments, <code>sem_getvalue()</code> will not return negative values if there are waiters on the semaphore.</p><p>The above code snippet is essentially what the NuttX <code>pthread_cond_broadcast()</code> does (see <a href="https://github.com/apache/nuttx/blob/master/sched/pthread/pthread_condbroadcast.c" target="_blank" rel="noreferrer">nuttx/sched/pthread_condbroadcast.c</a>). In NuttX condition variables are really just wrappers around semaphores that give them a few new properties. You could even call <code>pthread_cond_broadcast()</code> from an interrupt handler: See <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html" target="_blank" rel="noreferrer">http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_cond_signal.html</a> for usage information.</p><p>Neither of the above mechanisms are portable uses of these interfaces. However, there is no portable interface for communicating directly with interrupt handlers.</p><p>If you want to signal a single waiting thread, there are simpler things you an do. In the waiting task:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>semt_t g_mysemaphore;</span></span>
<span class="line"><span>volatile bool g_waiting;</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span></span></span>
<span class="line"><span>sem_init(&amp;g_mysemaphore);</span></span>
<span class="line"><span>sem_setprotocol(&amp;g_mysemaphore, SEM_PRIO_NONE);</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span></span></span>
<span class="line"><span>flags = enter_critical_section();</span></span>
<span class="line"><span>g_waiting = true;</span></span>
<span class="line"><span>while (g_waiting)</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>    ret = sem_wait(&amp;g_mysemaphore);</span></span>
<span class="line"><span>    ... handler errors ...</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>leave_critical_section(flags);</span></span></code></pre></div><p>In the above code snippet, interrupts are disabled to set and test <code>g_waiting</code>. Interrupts will, of course, be re-enabled automatically and atomically while the task is waiting for the interrupt event.</p><p>Then in the interrupt handler</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>extern semt_t g_mysemaphore;</span></span>
<span class="line"><span>extern volatile bool g_waiting;</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span></span></span>
<span class="line"><span>if (g_waiting)</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>    g_waiting = false;</span></span>
<span class="line"><span>    sem_post(&amp;g_mysemaphore);</span></span>
<span class="line"><span>}</span></span></code></pre></div><p>An integer type counter could also be used instead of a type bool to support multiple waitings. In that case, this is equivalent to the case above using <code>sem_getvalue()</code> but does not depend on non-portable properties of <code>sem_getvalue()</code>.</p><p>NOTE: There is possibility of improper interactions between the semaphore when it is used for signaling and priority inheritance. In this case, you should disable priority inheritance on the signaling semaphore using <code>sem_setprotocol(SEM_PRIO_NONE)</code>. See [[/guide](]{.title-ref}/guide.md)s/signaling_sem_priority_inheritance\` for further information.</p><h2 id="signals" tabindex="-1">Signals <a class="header-anchor" href="#signals" aria-label="Permalink to &quot;Signals&quot;">​</a></h2><blockquote><p>3) Store the thread id&#39;s in a list when <code>read()</code> is called. Wake up the threads using <code>sigqueue()</code>. Read the data from a shared buffer inside <code>sched_lock()</code>.</p></blockquote><p>Signals would work fine too. Signals have a side-effect that is sometimes helpful and sometimes a pain in the butt: They cause almost all kinds of waits (<code>read()</code>, <code>sem_wait()</code>, etc.) to wake up and return an error with <code>errno=EINTR</code>.</p><p>That is sometimes helpful because you can wake up a <code>recv()</code> or a <code>read()</code> etc., detect the event that generated the signal, and do something about it. It is sometimes a pain because you have to remember to handle the <code>EINTR</code> return value even when you don&#39;t care about it.</p><p>The POSIX signal definition includes some support that would make this easier for you. This support is not currently implemented in NuttX. The <code>kill()</code> interface for example (<a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/kill.html" target="_blank" rel="noreferrer">http://pubs.opengroup.org/onlinepubs/009695399/functions/kill.html</a>) supports this behavior:</p><p>&quot;If pid is 0, sig will be sent to all processes (excluding an unspecified set of system processes) whose process group ID is equal to the process group ID of the sender, and for which the process has permission to send a signal.</p><p>&quot;If pid is -1, sig will be sent to all processes (excluding an unspecified set of system processes) for which the process has permission to send that signal.&quot;</p><p>&quot;If pid is negative, but not -1, sig will be sent to all processes (excluding an unspecified set of system processes) whose process group ID is equal to the absolute value of pid, and for which the process has permission to send a signal.&quot;</p><p>NuttX does not currently support process groups. But that might be a good RTOS extension. If you and others think that would be useful I could probably add the basics of such a feature in a day or so.</p><h2 id="poll" tabindex="-1"><code>poll()</code> <a class="header-anchor" href="#poll" aria-label="Permalink to &quot;\`poll()\`&quot;">​</a></h2><blockquote><p>Is there some better way that I haven&#39;t discovered?</p></blockquote><p>The obvious thing that you did not mention is <code>poll()</code>. See <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/poll.html" target="_blank" rel="noreferrer">http://pubs.opengroup.org/onlinepubs/009695399/functions/poll.html</a> . Since you are writing a device driver, support for the <code>poll()</code> method in your driver seems to be the natural solution. See the <code>drivers/</code> directory for many examples, <code>drivers/pipes/pipe_common.c</code> for one. Each thread could simply wait on <code>poll()</code>; when the event occurs the driver could then wake up the set of waiters. Under the hood, this is again just a set of <code>sem_post</code>&#39;s. But it is also a very standard mechanism.</p><p>In your case, the semantics of <code>poll()</code> might have to be bent just a little. You might have to bend the meaning of some of the event flags since they are all focused on data I/O events.</p><p>Another creative use of <code>poll()</code> for use in cases like this:</p><blockquote><p>That would be something great! PX4 project has that implemented somehow (in C++), so maybe - if license permits - it could be ported to NuttX in no time?</p><p><a href="https://pixhawk.ethz.ch/px4/dev/shared_object_communication" target="_blank" rel="noreferrer">https://pixhawk.ethz.ch/px4/dev/shared_object_communication</a></p></blockquote><p>I don&#39;t know a lot about this, but it might be worth looking into if it matches your need.</p>`,52)]))}const m=a(o,[["render",i]]);export{u as __pageData,m as default};
